# Техническое видение проекта

## Технологии

- **Язык программирования**: Python
- **Telegram интеграция**: aiogram
- **LLM интеграция**: openrouter через реализацию openai client
- **Хранение данных**: In-memory (Python dict/list), без использования баз данных
- **Контейнеризация**: Docker
- **Тестирование**: pytest
- **Управление зависимостями**: uv
- **Автоматизация**: make

## Принцип разработки

- **KISS** (Keep It Simple, Stupid) - минимизация сложности на всех уровнях
- **MVP** (Minimum Viable Product) - только необходимые функции для проверки идеи
- **Итеративная разработка** - небольшие инкременты с быстрой обратной связью
- **Минимум зависимостей** - избегание лишних библиотек и фреймворков

## Структура проекта

```
llmstart_homework/
├── bot/                  # Основной код бота
│   ├── __init__.py
│   ├── main.py           # Точка входа
│   ├── handlers.py       # Обработчики сообщений Telegram
│   └── llm.py            # Интеграция с LLM
├── doc/                  # Документация
│   ├── product_idea.md   # Описание идеи продукта
│   └── vision.md         # Техническое видение
├── prompts/              # Системные промпты для LLM
│   └── system_prompt.txt # Основной системный промпт
├── tests/                # Тесты
│   ├── __init__.py
│   └── test_bot.py       # Тесты бота
├── .env                  # Файл с настройками и переменными окружения
├── .env.example          # Пример файла с настройками
├── .gitignore            # Файлы для игнорирования Git
├── Dockerfile            # Конфигурация Docker
├── Makefile              # Команды для автоматизации
├── README.md             # Общее описание проекта
└── requirements.txt      # Зависимости проекта
```

## Архитектура проекта

Архитектура проекта следует принципу KISS и включает минимально необходимые компоненты для работы Telegram-бота с LLM:

1. **Telegram-бот** (aiogram) - обрабатывает взаимодействие с пользователями
2. **Обработчики сообщений** - формируют запросы к LLM, сохраняют историю диалога
3. **Хранение истории** - in-memory хранилище на базе Python dict/list
4. **LLM интеграция** - отправляет запросы к openrouter через openai client
5. **Системный промпт** - предоставляет контекст и базу знаний для LLM



## Модель данных

В соответствии с принципом KISS используем простые структуры Python без внешних баз данных:

### Структура сообщения
```python
{
    "role": str,       # Одна из трех ролей: "system", "user" или "assistant"
    "content": str,    # Текстовое содержимое сообщения
    "timestamp": float # Время создания сообщения (опционально)
}
```

### Структура диалога
```python
[
    {"role": "system", "content": "Системный промпт..."},
    {"role": "user", "content": "Вопрос пользователя..."},
    {"role": "assistant", "content": "Ответ ассистента..."},
    # ... дополнительные сообщения диалога ...
]
```

### Структура пользовательских сессий
```python
{
    "user_id_1": {
        "chat_id": int,           # ID чата в Telegram
        "messages": [],           # Список сообщений диалога (см. структуру выше)
        "last_activity": float,   # Время последней активности
        "metadata": {}            # Дополнительная информация о сессии (опционально)
    },
    "user_id_2": {
        # ...
    }
}
```

Такая простая модель данных позволит хранить всю необходимую информацию в памяти и легко обрабатывать диалоги с пользователями.

## Работа с LLM

Для интеграции с языковой моделью применяем простой и эффективный подход:

1. **Клиент OpenAI** для обращения к openrouter
2. **Системный промпт** содержит всю базу знаний о компании и услугах
3. **Сохранение и отправка истории диалога** для обеспечения контекста при генерации ответов

### Основной процесс работы с LLM:

1. Загрузка системного промпта из файла
2. Формирование запроса с системным промптом и историей диалога
3. Отправка запроса к openrouter через openai client
4. Получение и обработка ответа
5. Сохранение ответа в истории диалога

## Мониторинг LLM

В соответствии с принципом минимализма реализуем только базовый мониторинг:

- **Логирование запросов и ответов** - сохранение всех взаимодействий с LLM для последующего анализа

Этот простой подход позволит отслеживать работу системы и при необходимости расширить мониторинг в будущем.

## Сценарии работы

В соответствии с принципом KISS выделяем два основных сценария работы бота:

### 1. Приветствие и первичная консультация клиентов

1. Пользователь начинает диалог с ботом
2. Бот приветствует пользователя и представляет компанию
3. Бот спрашивает о потребностях/проблемах пользователя
4. Пользователь описывает свою ситуацию
5. Бот анализирует запрос и задает уточняющие вопросы
6. Бот предлагает релевантные услуги на основе полученной информации

### 2. Ответы на типовые вопросы с предложением релевантных услуг

1. Пользователь задает конкретный вопрос о компании или услугах
2. Бот анализирует вопрос и определяет тематику
3. Бот предоставляет информацию по заданному вопросу
4. Бот предлагает связанные услуги компании, релевантные запросу
5. При необходимости бот отвечает на дополнительные уточнения

## Деплой

Используем Docker для упрощения процесса деплоя:

1. **Сборка Docker-образа** с приложением и всеми зависимостями
2. **Запуск контейнера** на целевом сервере
3. **Настройка перезапуска** контейнера при сбоях

Такой подход обеспечивает:
- Изоляцию приложения и его зависимостей
- Простоту переноса между окружениями
- Быстрое развертывание и обновление

## Подход к конфигурированию

В соответствии с принципом KISS используем максимально простой подход к конфигурированию:

1. **Файл `.env`** - содержит все настройки приложения, включая токены API и другие параметры
2. **Файл `.env.example`** - содержит пример настроек для локальной разработки без секретных данных

Такой подход обеспечивает:
- Единое место для всех конфигураций
- Простота настройки и поддержки
- Безопасное хранение секретных данных

## Подход к логгированию

Для логирования используем стандартный модуль Python `logging` без дополнительных зависимостей:

1. **Базовое логирование** в консоль и файл
2. **Разные уровни логирования** для разных компонентов системы
3. **Логирование запросов и ответов к LLM** для мониторинга и отладки

Такой минималистичный подход позволит:
- Отслеживать работу системы
- Находить и исправлять ошибки
- Анализировать взаимодействие с пользователями